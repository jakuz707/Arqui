<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta charset="utf-8" />
    <title>Unidad 4</title>
    <link rel="stylesheet" href="diseño.css">
</head>
<body>
    <div class="container">
        <header>
            <nav>
                <ul class="navbar">
                    <li><a href="index.html">Inicio</a></li>
                    <li><a href="Unidad1.html">Unidad 1</a></li>
                    <li><a href="Unidad2.html">Unidad 2</a></li>
                    <li><a href="Unidad3.html">Unidad 3</a></li>
                    <li><a href="Unidad4.html">Unidad 4</a></li>
                    <li><a href="Practicas.html">Prácticas</a></li>
                </ul>
            </nav>
        </header>
        <main class="hero">
            <h2>4.1 Aspectos básicos de la computación paralela</h2><hr />
            <br>
            La computación paralela busca dividir tareas grandes en tareas más pequeñas que se ejecutan simultáneamente en varios procesadores. Esto mejora el rendimiento y reduce el tiempo de procesamiento.<br><br>
            Conceptos clave:<br><br>
            Procesamiento paralelo: Ejecutar varias operaciones simultáneamente.<br>
            Procesador: Unidad que realiza los cálculos. Puede ser una CPU o GPU.<br>
            Hilos (threads): Subprocesos dentro de un programa que pueden ejecutarse en paralelo.<br><br>
            <br />
            <img src="images/18.png" width="400">
            <h2>4.2 Tipos de computación paralela</h2><hr />
            <br>
            <h3>4.2.1 Clasificación</h3><br>
            Se clasifica según la estructura del hardware o el modelo de programación:<br><br>
            SISD (Single Instruction, Single Data): Una sola instrucción trabaja sobre un solo dato.<br>
            SIMD (Single Instruction, Multiple Data): Una instrucción trabaja en paralelo sobre varios datos.<br>
            MISD (Multiple Instruction, Single Data): Varias instrucciones trabajan sobre un único flujo de datos.<br>
            MIMD (Multiple Instruction, Multiple Data): Varias instrucciones trabajan sobre diferentes datos en paralelo.<br><br>
            <br />
            <img src="images/19.gif" width="400">
            <h3>4.2.2 Arquitectura de computadoras secuenciales</h3><br>
            Computadoras secuenciales: Procesan una tarea a la vez en un único flujo de control.<br>
            Ejecución de instrucciones sigue un flujo lógico paso a paso.<br><br>
            <br />
            <img src="images/20.png" width="400">
            <h3>4.2.3 Organización de direcciones de memoria</h3><br>
            Memoria compartida: Todos los procesadores acceden a un espacio común.<br>
            Memoria distribuida: Cada procesador tiene su propia memoria y se comunican entre sí.<br>
            Memoria jerárquica: Combina memoria rápida y lenta para optimizar la velocidad de acceso.<br><br>

            <h2>4.3 Sistemas de memoria multiprocesadores</h2><hr />
            <br>
            <h3>4.3.1 Redes de interconexión dinámica (indirecta)</h3><br>
            Redes que conectan procesadores y memoria mediante conmutadores que cambian las rutas según la necesidad.<br><br>
            Ejemplo: Redes tipo Banyan, Omega o Crossbar.<br>
            Permiten comunicación eficiente entre varios procesadores y la memoria.<br><br>

            <h2>4.4 Sistemas de memoria distribuida</h2><hr />
            <br>
            <h3>4.4.1 Redes de interconexión estáticas</h3><br>
            Redes con conexiones fijas entre procesadores, sin conmutadores.<br><br>
            Ejemplo: Topologías como anillo, malla, hipercubo.<br>
            Ofrecen alta predictibilidad y escalabilidad.<br><br>

            <h2>4.5 Casos para estudio</h2><hr />
            <br>
            Supercomputadoras: Usan procesamiento paralelo para cálculos complejos (ejemplo: predicciones climáticas).<br>
            GPU (Unidades de Procesamiento Gráfico): Optimizadas para tareas de paralelismo masivo como gráficos y aprendizaje automático.<br>
            MapReduce: Modelo de programación paralelo para procesamiento de grandes volúmenes de datos en clústeres.<br><br>

        </main>
        <footer>
            <div class="footer-contact">
                <h3>Contacto</h3>
                <p>Correo: <a href="mailto:L22050752@saltillo.tecnm.mx">L22050752@saltillo.tecnm.mx</a></p>
                <p>Redes Sociales:</p>
                <ul class="social-links">
                    <li><a href="https://www.instagram.com/jazkwm" target="_blank">Instagram</a></li>
                    <li><a href="https://github.com/jakuz707" target="_blank">GitHub</a></li>
                </ul>
            </div>
            <div class="footer-credits">
                <p>Sofía Jazmín González Cázares </p>
            </div>
        </footer>

    </div>
</body>
</html>